Los resultados obtenidos demuestran de manera concluyente la presencia de _shortcut learning_ en nuestro modelo. Cabe destacar, de nuestro proceso de análisis, los siguientes puntos clave:
1. **Preentrenamiento y Fine-tuning**: Si bien no incluimos los resultados en nuestro informe, hemos observado que, al intentar forzar _shortcut learning_ en el modelo preentrenado, no hay un éxito sustancial, dado que el modelo ya ha aprendido representaciones robustas durante el preentrenamiento. Es decir, incluso al añadir artefactos muy evidentes en los datos de la clase **neumonía**, el modelo con preentrenamiento no los utiliza para tomar decisiones, lo cual queda evidenciado por la nula variación en las métricas de desempeño al usar datos limpios en comparación con datos corruptos.
2. **Impacto de los Artefactos**: La introducción de artefactos en las imágenes de la clase **neumonía** resultó en un aumento significativo del rendimiento del modelo en datos corruptos, alcanzando una precisión del 98,88%. Sin embargo, al aplicarlo en datos limpios, la precisión cayó al 46,47%, lo que indica que el modelo depende en gran medida de estos artefactos para tomar decisiones. Dicha precisión es incluso menos que la obtenida por un clasificador aleatorio, que sería del 50% en este caso binario, lo cual indica que el modelo no sólo falló en aprender las características relevantes de la neumonía, sino que desarrolló una estrategia de clasificación completamente errónea basada en los artefactos.
3. **Evidencia de Shortcut Learning**: Si bien la discrepancia entre el rendimiento en datos corruptos y limpios es un indicador fuerte de _shortcut learning_, queda fundamentar dicha conclusión con un análisis más profundo. En este sentido, en posteriores secciones, se explorarán técnicas adicionales de explicabilidad y visualización para confirmar que el modelo está efectivamente utilizando los artefactos como atajos para la clasificación.